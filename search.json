[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "FastAI Journey Status\n\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Lecture 01\n\n\n\n\n\n\n\nNotes\n\n\nFastAI\n\n\nHistory\n\n\nNeural Network\n\n\nTheory\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Snippets 01\n\n\n\n\n\n\n\nNotes\n\n\nFastAI\n\n\nUtils\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Setup; Understanding Tools\n\n\n\n\n\n\n\nNotes\n\n\nFastAI\n\n\nTools\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Notes\n\n\n\n\n\n\n\nnotes\n\n\nFastAI\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Journey\n\n\n\n\n\n\n\nFolder\n\n\nDeepLearning\n\n\nFastAI\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nQuarto ipynb blog test\n\n\n\n\n\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Notes/FastAI/index.html",
    "href": "posts/Notes/FastAI/index.html",
    "title": "FastAI Notes",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\nDate\n\n\n\n\n\n\nFastAI Lecture 01\n\n\n\n\n\nDec 31, 2023\n\n\n\n\nFastAI Setup; Understanding Tools\n\n\n\n\n\nDec 29, 2023\n\n\n\n\nFastAI Snippets 01\n\n\n\n\n\nDec 31, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Setup.html",
    "href": "posts/Notes/FastAI/FastAI Setup.html",
    "title": "FastAI Setup; Understanding Tools",
    "section": "",
    "text": "We‚Äôll be taking a look at package managers like conda, mamba; peek on some important tools like bash, tmux etc."
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Setup.html#setting-up-windows-subsystem",
    "href": "posts/Notes/FastAI/FastAI Setup.html#setting-up-windows-subsystem",
    "title": "FastAI Setup; Understanding Tools",
    "section": "Setting up Windows Subsystem",
    "text": "Setting up Windows Subsystem\n\nSet wsl\nget the miniforge/mambaforge(deprected)\nrun the miniforge.sh\nmamba install ipython\nmamba install jupyter lab\nmamba install pytorch\nconda install fastai"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Setup.html#nvidia-smi",
    "href": "posts/Notes/FastAI/FastAI Setup.html#nvidia-smi",
    "title": "FastAI Setup; Understanding Tools",
    "section": "nvidia-smi",
    "text": "nvidia-smi\nnvidia-smi dmon: Chec for sm and mem column ## Jupter %%debug : Used for non-graphical debugging from pdb import set_trace : set_trace() sets a breakpoint and automatically enables debugger mode ## Symblinks ### Linux ln -s target-path : Creates a symblink of the target directory in current directory ln -la : Displays the folders who are made up of symblink\n\nWindows\nYoutube Tutorial"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Setup.html#cloud-environments",
    "href": "posts/Notes/FastAI/FastAI Setup.html#cloud-environments",
    "title": "FastAI Setup; Understanding Tools",
    "section": "Cloud Environments",
    "text": "Cloud Environments\n\nPaperspace\nQ. How to set common library? 1. pip install --user with this flag so that the lib is installed in .local 2. move the .local to /storage/.local 3. create symblink from /storage/.local as target and it would create .bash.local in storage which would fire up time new instance has been called"
  },
  {
    "objectID": "posts/FastAI/Status.html",
    "href": "posts/FastAI/Status.html",
    "title": "FastAI Journey Status",
    "section": "",
    "text": "Live Coding:\nCompleted : 1,2,3,6,7\n\n\n\nLesson\n\n‚úÖ Done\nüåÄ Current Sprint\nüí§ Pending\n\n\n\n\n\n\n\n\n\n\n\n\nLesson\nWatched\nRead\nQuestionnaire\nRe-Implementation\nSelf-Implementation\n\n\n\n\n1\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nüåÄ\n\n\n2\n‚úÖ\n‚úÖ\nüåÄ\n‚úÖ\nüí§\n\n\n3\n\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n5"
  },
  {
    "objectID": "notesIndex.html",
    "href": "notesIndex.html",
    "title": "Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 29, 2023\n\n\nFastAI Notes\n\n\nAgastya Patel\n\n\n\n\nDec 29, 2023\n\n\nFastAI Setup; Understanding Tools\n\n\nAgastya Patel\n\n\n\n\nDec 31, 2023\n\n\nFastAI Snippets 01\n\n\nAgastya Patel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I‚Äôm Agastya. Welcome to my second brain which I share over internet.\nI‚Äôm currently working as Technical Artist and Developer. My responsibility involves developing custom in house solutions also whilst leveraging power of open source models for the creative team. I‚Äôm currently working on shot tracking product with the cloud team.\nMy interst in deep learning has been growing over me since I started using open source models which have lead into learning about it. I believe in constant learning and hence this is a good platform for sharing what I‚Äôm currently working/learning about.\nTech Stack\n- Python, Javascript, C++, SQL, HTML -\n- Framework/libs FastAI, PyQT, Flask, DCC Based APIs -\n- DCC: Blender, Unreal, Houdini, Maya -"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blogs",
    "section": "",
    "text": "FastAI Journey Status\n\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Lecture 01\n\n\n\n\n\n\n\nNotes\n\n\nFastAI\n\n\nHistory\n\n\nNeural Network\n\n\nTheory\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Snippets 01\n\n\n\n\n\n\n\nNotes\n\n\nFastAI\n\n\nUtils\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Setup; Understanding Tools\n\n\n\n\n\n\n\nNotes\n\n\nFastAI\n\n\nTools\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Notes\n\n\n\n\n\n\n\nnotes\n\n\nFastAI\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Journey\n\n\n\n\n\n\n\nFolder\n\n\nDeepLearning\n\n\nFastAI\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\n  \n\n\n\n\nQuarto ipynb blog test\n\n\n\n\n\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2023\n\n\nAgastya Patel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/FastAI/index.html",
    "href": "posts/FastAI/index.html",
    "title": "FastAI Journey",
    "section": "",
    "text": "Here‚Äôs my current journey of Fast AI learning. I‚Äôll be keeping tab of the projects and the current status of journey here!.\nMy FastAI/Course Journey: github\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\nDate\n\n\n\n\n\n\nFastAI Journey Status\n\n\n\n\n\nDec 31, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Lecture 01.html",
    "href": "posts/Notes/FastAI/FastAI Lecture 01.html",
    "title": "FastAI Lecture 01",
    "section": "",
    "text": "Useful Resources Alliance MAP JH‚Äôs jupyter NB 101 Kaggle: Comprehensive data exploration with Python‚Äù\nLesson1 Notes : 07/12/2023 - learn about functional programming - What is fine tuning?"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Lecture 01.html#history-of-neural-network",
    "href": "posts/Notes/FastAI/FastAI Lecture 01.html#history-of-neural-network",
    "title": "FastAI Lecture 01",
    "section": "History of Neural Network",
    "text": "History of Neural Network\n\nWarren McCulloch, Walter Pitts: Developed mathematical model of artificial neuron. Logical Calculus of the ideas immanent in Nervous Activity ;Defined ‚Äúall-or-none‚Äù characteristic of neuron; can be represented using simple addition and thresholding.\nRosenblatt Built artificial neuron - ‚ÄòMark I Perceptron‚Äô using above principles; Machine capable of recognizing and identifying its surrounding (Simple features) without human training and supervision.\n\n\nAI Winter #1\n\nMarvin Minsky wrote a book ‚ÄòPerceptron‚Äô and conveyed that single layer of these devices were unable to learn simple mathematical function like XOR. But also proposed that use of multiple layers would remove this limitation.\nWorld looked at the first of his outcome and research depleted for 2 decades.\nParallel Distribution Processing‚Äôs idea of using computational framework for modeling cognitive processing similar to brain.\n\n\nPDP‚Äôs approach still being used today in creating modern neural networks\nA set of processing units state of activation output function for each unit/node pattern of connectivity, rule for propagating patterns of activity in the network activation rule for combining the inputs at a node with current state to produce output for that node learning rule where connection patterns are modified with experience environment where system can operate\n\n\n\nAI Winter #2\n\nWith PDP‚Äôs approach, researchers started adding another layer in network but due to being complex, large and slow in nature; the field got deserted.\n\n\n\nToday\n\nMultiple layers of networks are being built due to technological advancements, data availability and better algorithm. The performance has increased drastically.\n\n\nPaper ^50k citations written by Alec Radford ‚ÄúUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks‚Äù [READ PENDING]\nMusk - ‚Äúhttps://twitter.com/elonmusk/status/1224089444963311616‚Äù\n\n\nGPU (Graphics Card) - Special kind of processors that handles thousands of single task at the same time. These tasks are similar to neural networks do, such that GPU‚Äô‚Äôs run neural network much faster than CPU"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Lecture 01.html#what-is-machine-learning",
    "href": "posts/Notes/FastAI/FastAI Lecture 01.html#what-is-machine-learning",
    "title": "FastAI Lecture 01",
    "section": "What is machine learning?",
    "text": "What is machine learning?\nDiscipline where we define program not by writing it ourself but by allowing it to learn from data and experience. ### What is deep learning? - A general & modern discipline of ML Deep learning is a computer technique to extract and transform data. It is based on multiple layer of neural network and these network are trained to minimize error and maximize accuracy."
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Lecture 01.html#arthur-samuel-ibms-research",
    "href": "posts/Notes/FastAI/FastAI Lecture 01.html#arthur-samuel-ibms-research",
    "title": "FastAI Lecture 01",
    "section": "Arthur Samuel, IBM‚Äôs research",
    "text": "Arthur Samuel, IBM‚Äôs research\n\n‚ÄúArtificial Intelligence: A frontier of Automation‚Äù\nProgramming a computer for complex computation like recognition is difficult task not because of complexity in the computer but because of the need specify every minute step of the process in detail.\nIdea: Instead of telling computer each step require to solve; we show examples f problems to solve and let it figure out how to solve it.\nThis was effective in his checker playing program which learned to play by learning from experience.\n\n\n[!idea] Breaking down his idea Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would ‚Äòlearn‚Äô from it‚Äôs experience."
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Lecture 01.html#getting-into-details-about-samuels-idea-for-ml",
    "href": "posts/Notes/FastAI/FastAI Lecture 01.html#getting-into-details-about-samuels-idea-for-ml",
    "title": "FastAI Lecture 01",
    "section": "Getting into details about Samuel‚Äôs Idea for ML",
    "text": "Getting into details about Samuel‚Äôs Idea for ML\n\nWeights / Model Parameters\n\nWeights are variables and weights assignment is a particular values in those variables.\nWeights are additional values which define how the program will operate.\nAltering the weights can change the model‚Äôs behavior.\n\n\n\n\n\nflowchart LR\n    I[Inputs] --&gt;M{Model} \n    W(Weights) --&gt; M\n    M --&gt;F[Resut]\n\n\n\n\n\nContextual Example: different weights in checker program would result in different checkers playing strategies\n\n\nActual Performance\n\nActual performance in checker playing program would be how well does the program plays\n\n\n\nAutomatic means of testing\n\nSet two checker playing models to play against each other and see which one is winning\n\n\n\nMechanism for altering the weight assignment so as to maximize the performance\n\nDifference in the weights of the winning model and losing model; and adjusting the weights little further in the winning direction\n\n\n\n\n\n\n  Machine programmed to learn from experience  \n\nmodel\n\n    architecture   \n\npredictions\n\n predictions   \n\nmodel-&gt;predictions\n\n    \n\ninputs\n\n inputs   \n\ninputs-&gt;model\n\n    \n\nloss\n\n loss   \n\npredictions-&gt;loss\n\n    \n\nparameters\n\n parameters   \n\nparameters-&gt;model\n\n    \n\nlabels\n\n labels   \n\nlabels-&gt;loss\n\n    \n\nloss-&gt;parameters\n\n  update  \n\n\n\n\n\n\n\nOnce Model has been trained\nWe pack the parameters/weights as being part of the model as we won‚Äôt be changing that. The model used for prediction is know as Inferenece\n\n\n\n\n\n  Inference (Trained Model + Fixed Weight)  \n\nInference\n\n    Inference   \n\npredictions\n\n predictions   \n\nInference-&gt;predictions\n\n    \n\ninputs\n\n inputs   \n\ninputs-&gt;Inference"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Lecture 01.html#neural-networks",
    "href": "posts/Notes/FastAI/FastAI Lecture 01.html#neural-networks",
    "title": "FastAI Lecture 01",
    "section": "Neural Networks",
    "text": "Neural Networks\n\nThese are Universal Function which can solve any problem just by varying its weights.\nIf you regard Neural network as a mathematical function, it turns out to be a extremely variable function depending on its weights. &gt; A mathematical proof called the universal approximation theorem shows that this function can solve any problem to any level of accuracy in theory.\n\nThe fact that neural networks are so flexible means that, in practice, they are often a suitable kind of model, and you can focus your effort on the process of training them‚Äîthat is, of finding good weight assignments.\n\nSearch for mechanism which can automatically update the weights according to problem\nStochastic gradient descent(SGD)\nNeural networks are special because they are highly flexible, which means they can solve an unusually wide range of problems just by finding the right weights. And SGD provides us a way to find those values automatically!\n\n\n\n\n\n\n\nCase : Cat vs Dog Classifier\nSamuel‚Äôs Machine Learning Model\n\n\n\n\nInput Images\nInputs\n\n\nWeights in neural network\nWeights\n\n\nResult (‚ÄòDog‚Äô/‚ÄòCat‚Äô)\nResult\n\n\nActual Performance at predicting the correct answer\nAutomatic means of testing effectiveness of current weights\n\n\nUpdating weights\nSGD mechanism of updating weights"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Snippets.html",
    "href": "posts/Notes/FastAI/FastAI Snippets.html",
    "title": "FastAI Snippets 01",
    "section": "",
    "text": "Page contains some of the common and usefull snippets. Pathlib, parallel processing."
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Snippets.html#path",
    "href": "posts/Notes/FastAI/FastAI Snippets.html#path",
    "title": "FastAI Snippets 01",
    "section": "Path",
    "text": "Path\nfrom pathlib import path\npath = Path() #Current Dir\n#path = Path('Content') #Relative Dir\n#path = Path('NB/content') #Absolute Dir"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Snippets.html#add-recent-models",
    "href": "posts/Notes/FastAI/FastAI Snippets.html#add-recent-models",
    "title": "FastAI Snippets 01",
    "section": "Add recent models",
    "text": "Add recent models\n!pip install timm\nimport timm\ntimm.list_models('convnext*) # Prints available model"
  },
  {
    "objectID": "posts/Notes/FastAI/FastAI Snippets.html#fine_tune",
    "href": "posts/Notes/FastAI/FastAI Snippets.html#fine_tune",
    "title": "FastAI Snippets 01",
    "section": "Fine_Tune:",
    "text": "Fine_Tune:\nFine Tune Freezes the weights of all layers except the last layers. Calls fit on the last layer Decreases the learning rate Unfreezes the model Fit for number of epoch specified\n\nhalf precision floating points (less precise but fast) supported on latest gpus .to_fp16() (method for learnerer)\n\n\n[!info] Learning rate and lr_find() : Is used to find good learning rate"
  },
  {
    "objectID": "posts/QuickStart.html",
    "href": "posts/QuickStart.html",
    "title": "Quarto ipynb blog test",
    "section": "",
    "text": "Quarto JP Notebook\n\nfrom fastai.vision.all import *\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n\nUsing device: cuda\n\n\n\npath = untar_data(URLs.PETS)/'images'\n\nDownloading a new version of this dataset...\n\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 18:21&lt;00:00]\n    \n    \n\n\n\n\ndef is_cat(x): return x[0].isupper()\ndls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat, item_tfms=Resize(224))\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)\n\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/agastya/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:14&lt;00:00, 6.18MB/s]\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.166146\n0.011790\n0.004060\n00:42\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.053903\n0.018103\n0.003383\n00:47"
  }
]